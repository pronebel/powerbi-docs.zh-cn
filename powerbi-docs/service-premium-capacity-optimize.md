---
title: 优化 Microsoft Power BI Premium 容量
description: 介绍 Power BI Premium 容量的优化策略。
author: davidiseminger
ms.author: davidi
ms.reviewer: ''
ms.service: powerbi
ms.subservice: powerbi-admin
ms.topic: conceptual
ms.date: 04/09/2019
ms.custom: seodec18
LocalizationGroup: Premium
ms.openlocfilehash: 4d03419105244b7fddafea3b26b69e4f4f5f874c
ms.sourcegitcommit: 6272c4a0f267708ca7d38a45774f3bedd680f2d6
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 01/06/2020
ms.locfileid: "74958531"
---
# <a name="optimizing-premium-capacities"></a>优化高级容量

出现高级容量性能问题时，常见的首选方法是优化或调整解决方案，重获可接受的响应时间。 理由是避免购买额外的高级容量，除非有正当理由。

需要额外的高级容量时，可选择本文中描述的两种选项：

- 扩大现有的高级容量
- 添加新的高级容量

最后，以测试方法和高级容量大小调整结束本文。

## <a name="best-practices"></a>最佳做法

尝试获得最佳利用率和性能时，有一些建议的最佳做法可供选择，包括：

- 使用工作区而非个人工作区。
- 将业务关键型和自助式 BI (SSBI) 分入不同的容量。

  ![将业务关键型和自助式 BI 分入不同的容量](media/service-premium-capacity-optimize/separate-capacities.png)

- 如果仅与 Power BI Pro 用户共享内容，则可能无需将内容存储到专用容量中。
- 在想要实现特定刷新时间或需要特定功能时，使用专用容量。 例如，使用大型数据集或分页报表时。

### <a name="addressing-common-questions"></a>解决常见问题

优化 Power BI Premium 部署非常复杂，涉及到对工作负载要求、可用资源及其有效使用的理解。

本文讨论了七大常见支持问题、阐述了可能存在的问题和解释，并介绍了如何识别和解决问题。

### <a name="why-is-the-capacity-slow-and-what-can-i-do"></a>为什么容量会变慢，而我又该怎么办？

导致高级容量变慢的原因有很多。 这个问题要求你通过更多信息来理解“慢”的含义。 报表加载速度慢吗？ 还是报表加载失败？ 用户与报表交互时，报表视觉对象的加载速度或更新速度慢吗？ 刷新是否需要比预期或比以前更长的时间才能完成？

了解原因后，就可以开始调查了。 请回答以下 6 个问题，这有助于处理更具体的问题。

### <a name="what-content-is-using-up-my-capacity"></a>哪些内容占用了我的容量？

可使用 Power BI Premium 容量指标应用按容量进行筛选，并查看工作区内容的性能指标  。 对于存储在高级容量中的所有内容，可以按小时查看其在过去 7 天内的性能指标和资源使用情况。 在排查有关高级容量性能的一般性问题时，监视通常是要采取的第一步操作。

要监视的关键指标包括：

- 平均 CPU 和高利用率计数。
- 平均内存和高利用率计数，以及特定数据集、数据流和分页报表的内存使用情况。
- 在内存中加载的活动数据集。
- 平均和最长的查询持续时间。
- 平均查询等待时间。
- 平均数据集和数据流刷新时间。

在 Power BI Premium 容量指标应用中，活动内存显示向某报表提供的内存总量，由于在过去三分钟内一直在使用该报表，因此无法将其逐出。 刷新等待时间的高峰值可能与大型和/或活动的数据集相关。

“按平均持续时间排名前五”图表突出显示占用容量资源的前 5 个数据集、分页报表和数据流  。 排名前五的列表中的内容将列入调查候选项且可能进行优化。

### <a name="why-are-reports-slow"></a>报表速度为何会变慢？

下表显示了可能的问题及其确定和处理方法。

#### <a name="insufficient-capacity-resources"></a>容量资源不足

| 可能的解释 | 确定方法 | 解决方法 |
| --- | --- | --- |
| 总活动内存高（由于过去三分钟内在使用模型，因此无法将其逐出）。<br><br> 查询等待时间内出现多次高峰。<br><br> 刷新等待时间内出现多次高峰。 | 监视内存指标 \[[1](#endnote-1)\] 和逐出计数 \[[2](#endnote-2)\]。 | 缩小模型大小或转换为 DirectQuery 模式。 请参阅本文的[优化模型](#optimizing-models)部分。<br><br> 扩大容量。<br><br> 将内容分配到其他容量。 |

#### <a name="inefficient-report-designs"></a>报表设计效率低下

| 可能的解释 | 确定方法 | 解决方法 |
| --- | --- | --- |
| 报表页包含太多视觉对象（交互式筛选可按每个视觉对象触发至少一个查询）。<br><br> 视觉对象检索的数据量超出必需量。 | 审核报表设计。<br><br> 与报表用户面谈，了解他们如何与报表互动。<br><br> 监视数据集查询指标 \[[3](#endnote-3)\]。 | 重新设计报表，减少每页的视觉对象。 |

#### <a name="dataset-is-slow-especially-when-reports-have-previously-performed-well"></a>数据集速度缓慢，尤其是在报表之前表现良好的情况下

| 可能的解释 | 确定方法 | 解决方法 |
| --- | --- | --- |
| 导入数据越来越多。<br><br> 复杂或低效的计算逻辑，包括 RLS 角色。<br><br> 模型未完全优化。<br><br> (DQ/LC) 网关延迟。<br><br> DQ 源查询响应时间长。 | 审核模型设计。<br><br> 监视网关性能计数器。 | 请参阅本文的[优化模型](#optimizing-models)部分。 |

#### <a name="high-concurrent-report-usage"></a>并发报表使用率高

| 可能的解释 | 确定方法 | 解决方法 |
| --- | --- | --- |
| 查询等待时间长。<br><br> CPU 饱和。<br><br> 超出 DQ/LC 连接限制。 | 监视 CPU 使用率 \[[4](#endnote-4)\]、查询等待时间和 DQ/LC 利用率 \[[5](#endnote-5)\] 指标 + 查询持续时间。 如果起伏不定，则表示是并发问题。 | 扩大容量或将内容分配到其他容量。<br><br> 重新设计报表，减少每页的视觉对象。 |

**注意：**    
<a name="endnote-1"></a>\[1\] 平均内存使用率 (GB) 和最高内存占用率 (GB)。   
<a name="endnote-2"></a>\[2\] 数据集逐出。   
<a name="endnote-3"></a>\[3\] 数据集查询、数据集平均查询持续时间（毫秒）、数据集等待计数和数据集平均等待时间（毫秒）。   
<a name="endnote-4"></a>\[4\] CPU 高利用率计数和利用率最高的 CPU 时间（过去七天）。   
<a name="endnote-5"></a>\[5\] DQ/LC 高利用率计数和利用率最高的 DQ/LC 时间（过去七天）。   

### <a name="why-are-reports-not-loading"></a>为什么未加载报表？

如果报告加载失败，可确定容量的内存不足且容量过热。 主动查询所有已加载的模型并因此无法逐出模型，而且任何刷新操作都已暂停或延迟时，可能会发生此情况。 Power BI 服务将尝试加载数据集 30 秒，并向用户发出故障通知，建议其尽快重试。

目前，没有指标来监视报表加载故障。 可通过监视系统内存（特别是最高利用率和利用率最高的时间）来确定此问题出现的可能性。 数据集逐出率高和数据集刷新平均等待时间长都可能表示出现此问题。

如果该问题只是偶尔发生，则可能不被视为优先问题。 报表用户被告知服务繁忙且他们应稍后重试。 如果此情况的发生频率过高，可通过扩大高级容量或将内容分配到其他容量来解决问题。

容量管理员（和 Power BI 服务管理员）可监视“查询失败”指标，以确定此问题的发生时间  。 他们还可重启容量，在系统过载时重置所有操作。

### <a name="why-are-refreshes-not-starting-on-schedule"></a>为何未按计划开始刷新？

无法保证计划内刷新的开始时间。 回想一下，相对于后台操作，Power BI 服务将始终优先考虑交互操作。 而刷新是在满足以下两个条件时可能发生的后台操作：

- 内存充足
- 不会超出高级容量支持的并发刷新数

如果不满足以上条件，则刷新操作进入队列，直到满足条件。

再回想一下，要进行完全刷新，则至少需要当前数据集内存大小的两倍。 如果没有足够的内存可用，则在模型逐出释放内存之前不能开始刷新，这意味着在一个或多个数据集变为非活动状态并且可被逐出之前一直延迟。

回想一下，支持的最大并发刷新次数设置为后端 vCore 的 1.5 倍（已向上舍入）。

如果某计划内刷新无法在下一个计划内刷新即将开始之前启动，则该计划内刷新失败。 通过 UI 手动触发的按需刷新在失败前最多尝试运行三次。

容量管理员（和 Power BI 服务管理员）可监视“平均刷新等待时间（分钟）”指标，以确定计划时间与操作开始时间之间的平均延迟  。

虽然通常并非将管理视为优先，但确保有足够的内存才能影响按时数据刷新。 这可能涉及到将数据集隔离到具有已知足够资源的容量。 管理员也可以与数据集所有者协调，帮助错开或减少计划数据刷新时间，从而最大限度地减少冲突。 请注意，管理员无法查看刷新队列或检索数据集计划。

### <a name="why-are-refreshes-slow"></a>刷新速度为何缓慢？

刷新可能很慢，或者被认为是缓慢的（如前面的常见问题所述）。

刷新实际上很慢时，可能是由于以下几个原因造成的：

- CPU 不足（刷新可能会占用大量 CPU 资源）。
- 内存不足，导致刷新暂停（这需要在条件有利于重新开始时重新开始刷新）。
- 非容量原因，包括数据源系统响应能力、网络延迟、无效权限或网关吞吐量。
- 数据量 - 配置增量刷新的合理原因，如下所述。

容量管理员（和 Power BI 服务管理员）可以监视“平均刷新持续时间（分钟）”指标，以确定随时间进行比较的基准，也可以监视“平均刷新等待时间（分钟）”指标，以确定计划时间与操作开始时间之间的平均延迟   。

增量刷新可以显著减少数据刷新持续时间，尤其是对大型模型表来说。 增量刷新有 4 个优点：

- **刷新更快** - 只需加载表的一个子集（减少 CPU 和内存使用），即可在刷新多个分区时提高并行性。
- **仅在需要时进行刷新** - 增量刷新策略可配置为仅在数据发生更改时加载。
- **刷新更可靠** - 与易失性数据源系统的运行中连接时间更短，更不容易断开连接。
- **模型保持精简** - 增量刷新策略可配置为自动删除超出滑动时间范围的历史记录。

若要了解详细信息，请参阅 [Power BI Premium 中的增量刷新](service-premium-incremental-refresh.md)。

### <a name="why-are-data-refreshes-not-completing"></a>为什么无法完成数据刷新？

如果数据刷新开始但未能完成，则可能由以下几个原因造成：

- 内存不足，即使高级容量中只有一个模型也是如此，即模型非常大。
- 非容量原因，包括数据源系统断开连接、无效权限或网关错误。

容量管理员（和 Power BI 服务管理员）可以监视“因内存不足导致的刷新失败”指标  。

## <a name="optimizing-models"></a>优化模型

对于提供高效且可缩放的解决方案，优化模型设计至关重要。 但是，本文中不提供完整的讨论。 相反，本部分将提供在优化模型时需要考虑的关键方面。

### <a name="optimizing-power-bi-hosted-models"></a>优化 Power BI 托管模型

可在数据源和模型层优化托管在高级容量中的模型。

请考虑导入模型的优化可能性：

![导入模型的优化可能性](media/service-premium-capacity-optimize/import-model-optimizations.png)

在数据源层：

- 可对关系数据源进行优化，从而通过预先集成数据、应用适当的索引、定义与增量刷新周期一致的表分区，以及具体化计算（代替计算得出的模型表和列）或向视图添加计算逻辑，来确保刷新尽可能地快。
- 非关系数据源可与关系存储区预先集成。
- 请确保网关具有足够的资源（最好是在专用计算机上）、具有足够的网络带宽且非常靠近数据源。

在模型层：

- Power Query 查询设计可消除或最大程度减少复杂的转换，尤其是合并不同数据源的转换（数据仓库在其提取-转换-加载阶段实现这一点）。 此外，请确保设置适当的数据源隐私级别，这可避免要求 Power BI 加载完整结果来生成跨查询的组合结果。
- 模型结构决定要加载的数据并直接影响模型大小。 可进行设计，让模型结构通过删除列、删除行（尤其是历史数据）或通过加载汇总数据（代价是加载详细数据），来避免加载不必要的数据。 通过删除不能非常有效地存储或压缩的高基数列（尤其是文本列），可显著减小大小。
- 可通过配置单向关系提升模型查询性能，除非有令人信服的理由允许双向筛选。 还可考虑使用 [CROSSFILTER](https://docs.microsoft.com/dax/crossfilter-function) 函数，而不使用双向筛选。
- 聚合表可以通过加载预先汇总的数据来实现快速查询响应，但这会增加模型的大小并导致刷新时间更长。 通常，应保留聚合表，将其用于非常大型的模型或复合模型设计。
- 计算的表和列会增加模型大小，并导致刷新时间更长。 通常，在数据源中具体化或计算数据时，可减小存储大小并缩短刷新时间。 如果这不可行，使用 Power Query 自定义列可提供更好的存储压缩。
- 可能有机会针对度量值和 RLS 规则来调整 DAX 表达式，可能是重写逻辑来避免开销较高的公式
- 增量刷新可显著缩短刷新时间并节省内存和 CPU。 还可配置增量刷新，使其删除历史数据，保证模型大小精简。
- 存在互相冲突的不同查询模式时，可以将模型重新设计为两个模型。 例如，某些报表显示所有历史记录中的高级聚合，并且可以容忍 24 小时的延迟。 而其他报表涉及今天的数据，需要对各事务进行精细访问。 创建两个针对每个需求进行优化的模型，而不是设计单个模型来满足所有报表。

请考虑 DirectQuery 模型的优化可能性。 模型向基础数据源发出查询请求时，数据源优化对于响应式模型查询的提供至关重要。

 ![DirectQuery 模型的优化可能性](media/service-premium-capacity-optimize/direct-query-model-optimizations.png)

在数据源层：

- 可对数据源进行优化，从而通过预先集成数据（无法在模型层实现）、应用适当的索引、定义表分区、具体化汇总数据（借助索引视图）以及尽量减少计算量，来确保查询尽可能地快。 传递查询只需要筛选并在索引表或视图之间执行内部连接时，可以获得最佳体验。
- 请确保网关具有足够的资源（最好是在专用计算机上）、具有足够的网络带宽且非常靠近数据源。

在模型层：

- Power Query 查询设计最好不要应用任何转换，否则请尝试将转换数保持在最小绝对值。
- 可通过配置单向关系提升模型查询性能，除非有令人信服的理由允许双向筛选。 此外，模型关系应配置为假设强制执行引用完整性（若情况如此），并将使用更有效的内联而不是外部联接来完成数据源查询。
- 请不要创建 Power Query 查询自定义列或模型计算列，尽可能在数据源中实现这些列。
- 可能有机会针对度量值和 RLS 规则来调整 DAX 表达式，可能是重写逻辑来避免开销较高的公式。

请考虑复合模型的优化可能性。 回想一下，复合模型可实现导入和 DirectQuery 表的混用。

![复合模型的优化可能性](media/service-premium-capacity-optimize/composite-model-optimizations.png)

- 一般而言，导入和 DirectQuery 模型的优化适用于使用这些存储模式的复合模型表。
- 通常，通过将维度-类型表（表示业务实体）配置为双存储模式，将事实-类型表（通常是大型表，表示操作事实）配置为 DirectQuery 存储模式，努力实现均衡设计。 双存储模式是指导入模式和 DirectQuery 存储模式，这使 Power BI 服务能够确定在生成本机查询进行传递时要使用的最有效的存储模式。
- 请确保网关具有足够的资源（最好是在专用计算机上）、具有足够的网络带宽且非常靠近数据源
- 在用于汇总 DirectQuery 存储模式事实-类型表时，配置为导入存储模式的聚合表可显著提升查询性能。 在这种情况下，聚合表将增加模型大小并延长刷新时间，而通常这是为实现更快查询所能接受的权衡。

### <a name="optimizing-externally-hosted-models"></a>优化外部托管模型

[优化 Power BI 托管模型](#optimizing-power-bi-hosted-models)部分中讨论的许多优化可能性也适用于使用 Azure Analysis Services 和 SQL Server Analysis Services 开发的模型。 明显例外的是当前不支持的某些功能，包括复合模型和聚合表。

外部托管数据集的另一个考虑因素是与 Power BI 服务相关的数据库托管。 对于 Azure Analysis Services，这意味着在与 Power BI 租户（主区域）相同的区域中创建 Azure 资源。 对于 SQL Server Analysis Services，这意味着在同一区域中托管 VM（针对 IaaS），或者意味着确保高效的网关设置（针对本地）。

另外，可能需要注意的是，Azure Analysis Services 数据库和 SQL Server Analysis Services 表格数据库要求将其模型完全加载到内存中并将其一直保留在内存中以支持查询。 与 Power BI 服务相同的是，如果模型必须在刷新过程中保持联机状态，则需要有足够的内存用于刷新。 而与 Power BI 服务不同的是，模型不会根据使用情况自动进出内存。 因此，Power BI Premium 提供一种更有效的方法，通过降低内存使用率来最大化模型查询。

## <a name="capacity-planning"></a>容量规划

高级容量的大小决定其可用内存和处理器资源以及对容量的限制。 高级容量的数量也是一个考虑因素，因为创建多个高级容量可帮助隔离彼此的工作负载。 请注意，每个容量节点的存储空间为 100 TB，这对任何工作负载来说可能都已远远足够。

确定高级容量的大小和数量可能具有挑战性，尤其是对所创建的初始容量而言。 调整容量大小时，首先是了解表示预期日常使用情况的平均工作负载。 重要的是要了解并非所有工作负载都是相等的。 例如，一种极端情况是 100 个并发用户访问包含单个视觉对象的单个报表页，这很容易实现。 然而，另一种极端情况是 100 个并发用户访问 100 个不同的报表，每个报表的报表页上有 100 个视觉对象，这将对容量资源提出截然不同的要求。

因此，容量管理员需要考虑许多特定于环境、内容和预期使用情况的因素。 最重要的目标是在提供一致的查询时间、可接受的等待时间和逐出率的同时，最大化容量利用率。 需要考虑的因素包括：

- **模型大小和数据特征** - 必须将导入模型完全加载到内存中，这样才能进行查询或刷新。 LC/DQ 数据集需要大量的处理器时间，可能还需要大量内存，才能评估复杂度量值或 RLS 规则。 内存和处理器大小及 LC/DQ 查询吞吐量受容量大小的限制。
- **并发活动模型** - 不同的导入模型保留在内存中时，其并发查询将提供最佳响应和性能。 应提供足够的内存来托管所有查询量大的模型，并提供额外的内存来允许刷新。
- **导入模型刷新** - Power Query 查询和计算表/列逻辑的刷新类型（完整或增量）、持续时间和复杂性会影响内存，尤其会影响处理器使用情况。 并发刷新受到容量大小（1.5 x 后端 vCore，已向上舍入）的限制。
- **并发查询** - 处理器或 LC/DQ 连接超出容量限制时，许多并发查询可能导致报表无响应。 对于包含许多视觉对象的报表页而言尤其如此。
- **数据流和分页报表** - 容量可配置为支持数据流和分页报表，后者都需要可配置的最大容量内存百分比。 内存动态分配给数据流，但静态分配给分页报表。

除这些因素外，容量管理员还可以考虑创建多个容量。 多个容量允许隔离工作负载，并且可进行配置，使其确保优先级工作负载具有保证的资源。 例如，可创建两个容量，来将业务关键型工作负载与自助式 BI (SSBI) 工作负载分开。 业务关键型容量可用于隔离大型企业模型，这样可为其提供有保证的资源，将创作访问权限仅授予 IT 部门。 SSBI 容量可用于托管越来越多的小型模型，并允许业务分析师访问。 SSBI 容量有时可能会遇到可容忍的查询或刷新等待。

随着时间的推移，容量管理员可通过在工作区之间移动内容（或在容量之间移动工作区），以及通过增加或减少容量，在不同容量中平衡工作区。 通常，需要增加容量来托管较大的模型，需要横向扩展容量来实现更高的并发性。

回想一下，购买许可证可为租户提供 vCore。 可购买 P3 订阅来创建一个或多个高级容量（最多 4 个），即创建 1 个 P3、2 个 P2 或 4 个 P1  。 此外，在将 P2 容量扩大到 P3 容量之前，可考虑拆分 vCore 来创建两个 P1 容量。

## <a name="testing-approaches"></a>测试方法

确定容量大小后，可通过创建受控环境来执行测试。 可行且经济的选择是创建 Azure (SKU) 容量，请注意 P1 容量与 A4 容量的大小相等，P2 和 P3 容量分别与 A5 和 A6 容量的大小相等。 可以快速创建 Azure 容量，并按小时对其计费。 因此，测试完成后，即可轻松删除这些容量，避免产生费用。

可将测试内容添加到 Azure 容量上创建的工作区中，然后以单个用户的身份运行报表，以生成实际且具有代表性的查询工作负载。 如有导入模型，则还应对每个模型执行刷新操作。 然后，可使用监视工具来查看所有指标，了解资源利用率。

重要的是，测试是可重复的。 应运行几次测试，每次得出的结果应大致相同。 这些结果的平均值可用于推断和估算真实生产条件下的工作负载。

如果已有要进行负载测试的容量和报表，请使用 [PowerShell 负载生成工具](https://aka.ms/PowerBILoadTestingTool)快速生成负载测试。 借助该工具，可估算容量在一小时内可以运行的每个报表的实例数。 可使用该工具评估容量呈现单个报表或并行呈现多个不同报表的能力。 有关详细信息，请参阅视频 [Microsoft Power BI：高级容量](https://www.youtube.com/watch?time_continue=1860&v=C6vk6wk9dcw)。

要生成更复杂的测试，请考虑开发用于模拟实际工作负载的负载测试应用程序。 有关详细信息，请参阅网络研讨会 [Load Testing Power BI Applications with Visual Studio Load Test](https://powerbi.microsoft.com/blog/week-4-11-webinars-load-testing-power-bi-applications-with-visual-studio-load-test-and-getting-started-with-cds-for-apps-based-model-driven-apps/)（使用 Visual Studio 负载测试对 Power BI 应用程序进行负载测试）。

## <a name="acknowledgements"></a>致谢

本文由 Peter Myers、数据平台 MVP 和独立的 BI 专家通过 [Bitwise Solutions](https://www.bitwisesolutions.com.au/) 撰写。

## <a name="next-steps"></a>后续步骤

> [!div class="nextstepaction"]
> [高级容量方案](service-premium-capacity-scenarios.md)   
  
更多问题？ [尝试咨询 Power BI 社区](https://community.powerbi.com/)